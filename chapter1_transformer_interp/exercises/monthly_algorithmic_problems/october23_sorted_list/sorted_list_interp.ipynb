{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorted List\n",
    " October 2023 Monthly Algorithmic Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "* Fully reverse-engineer model\n",
    "* Create adversarial examples and explain how and why they work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import einops\n",
    "from eindex import eindex\n",
    "from pathlib import Path\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "chapter = r\"chapter1_transformer_interp\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = exercises_dir / \"monthly_algorithmic_problems\" / \"october23_sorted_list\"\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from monthly_algorithmic_problems.october23_sorted_list.dataset import SortedListDataset\n",
    "from monthly_algorithmic_problems.october23_sorted_list.model import create_model\n",
    "from plotly_utils import hist, bar, imshow\n",
    "\n",
    "device = t.device('mps' if t.backends.mps.is_available() else 'cuda' if t.cuda.is_available() else 'cpu')\n",
    "#device = t.device('cpu')\n",
    "print(\"using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = section_dir / \"sorted_list_model.pt\"\n",
    "\n",
    "model = create_model(\n",
    "    list_len=10,\n",
    "    max_value=50,\n",
    "    seed=0,\n",
    "    d_model=96,\n",
    "    d_head=48,\n",
    "    n_layers=1,\n",
    "    n_heads=2,\n",
    "    normalization_type=\"LN\",\n",
    "    d_mlp=None,\n",
    "    device=\"mps\"\n",
    ")\n",
    "\n",
    "state_dict = t.load(filename, weights_only=True, map_location=device)\n",
    "\n",
    "state_dict = model.center_writing_weights(state_dict)\n",
    "state_dict = model.center_unembed(state_dict)\n",
    "state_dict = model.fold_layer_norm(state_dict)\n",
    "state_dict = model.fold_value_biases(state_dict)\n",
    "model.load_state_dict(state_dict, strict=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that weight processing worked\n",
    "\n",
    "W_U_mean_over_input = einops.reduce(model.W_U, \"d_model d_vocab -> d_model\", \"mean\")\n",
    "t.testing.assert_close(W_U_mean_over_input, t.zeros_like(W_U_mean_over_input))\n",
    "\n",
    "W_U_mean_over_output = einops.reduce(model.W_U, \"d_model d_vocab -> d_vocab\", \"mean\")\n",
    "t.testing.assert_close(W_U_mean_over_output, t.zeros_like(W_U_mean_over_output))\n",
    "\n",
    "W_O_mean_over_output = einops.reduce(model.W_O, \"layer head d_head d_model -> layer head d_head\", \"mean\")\n",
    "t.testing.assert_close(W_O_mean_over_output, t.zeros_like(W_O_mean_over_output))\n",
    "\n",
    "b_O_mean_over_output = einops.reduce(model.b_O, \"layer d_model -> layer\", \"mean\")\n",
    "t.testing.assert_close(b_O_mean_over_output, t.zeros_like(b_O_mean_over_output))\n",
    "\n",
    "W_E_mean_over_output = einops.reduce(model.W_E, \"token d_model -> token\", \"mean\")\n",
    "t.testing.assert_close(W_E_mean_over_output, t.zeros_like(W_E_mean_over_output))\n",
    "\n",
    "W_pos_mean_over_output = einops.reduce(model.W_pos, \"position d_model -> position\", \"mean\")\n",
    "t.testing.assert_close(W_pos_mean_over_output, t.zeros_like(W_pos_mean_over_output))\n",
    "\n",
    "b_V = model.b_V\n",
    "t.testing.assert_close(b_V, t.zeros_like(b_V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model (examples from streamlit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "dataset = SortedListDataset(size=N, list_len=10, max_value=50, seed=43)\n",
    "\n",
    "logits, cache = model.run_with_cache(dataset.toks)\n",
    "logits: t.Tensor = logits[:, dataset.list_len:-1, :]\n",
    "\n",
    "targets = dataset.toks[:, dataset.list_len+1:]\n",
    "\n",
    "logprobs = logits.log_softmax(-1) # [batch seq_len vocab_out]\n",
    "probs = logprobs.softmax(-1)\n",
    "\n",
    "batch_size, seq_len = dataset.toks.shape\n",
    "logprobs_correct = eindex(logprobs, targets, \"batch seq [batch seq]\")\n",
    "probs_correct = eindex(probs, targets, \"batch seq [batch seq]\")\n",
    "\n",
    "avg_cross_entropy_loss = -logprobs_correct.mean().item()\n",
    "\n",
    "print(f\"Average cross entropy loss: {avg_cross_entropy_loss:.3f}\")\n",
    "print(f\"Mean probability on correct label: {probs_correct.mean():.3f}\")\n",
    "print(f\"Median probability on correct label: {probs_correct.median():.3f}\")\n",
    "print(f\"Min probability on correct label: {probs_correct.min():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(dataset: SortedListDataset, batch_idx: int):\n",
    "\n",
    "    logits: Tensor = model(dataset.toks)[:, dataset.list_len:-1, :]\n",
    "    logprobs = logits.log_softmax(-1) # [batch seq_len vocab_out]\n",
    "    probs = logprobs.softmax(-1)\n",
    "\n",
    "    str_targets = dataset.str_toks[batch_idx][dataset.list_len+1: dataset.seq_len]\n",
    "\n",
    "    imshow(\n",
    "        probs[batch_idx].T,\n",
    "        y=dataset.vocab,\n",
    "        x=[f\"{dataset.str_toks[batch_idx][j]}<br><sub>({j})</sub>\" for j in range(dataset.list_len+1, dataset.seq_len)],\n",
    "        labels={\"x\": \"Token\", \"y\": \"Vocab\"},\n",
    "        xaxis_tickangle=0,\n",
    "        title=f\"Sample model probabilities:<br>Unsorted = ({','.join(dataset.str_toks[batch_idx][:dataset.list_len])})\",\n",
    "        text=[\n",
    "            [\"ã€‡\" if (str_tok == target) else \"\" for target in str_targets]\n",
    "            for str_tok in dataset.vocab\n",
    "        ],\n",
    "        width=400,\n",
    "        height=1000,\n",
    "    )\n",
    "\n",
    "show(dataset, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
